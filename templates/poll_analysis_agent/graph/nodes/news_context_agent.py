# -*- coding: utf-8 -*-
"""
news_context_agent.py
ì—¬ë¡  ë³€ë™ì— ì˜í–¥ì„ ì¤€ ì£¼ìš” ë‰´ìŠ¤ë¥¼ ìë™ ìˆ˜ì§‘Â·ìš”ì•½
"""

import os
import json
from datetime import datetime
from bs4 import BeautifulSoup
import requests
from openai import OpenAI

# === ê¸°ë³¸ ê²½ë¡œ ì„¤ì • ===
BASE_DIR = r"D:\ai-edu-stack\templates\poll_analysis_agent"
OUTPUT_DIR = os.path.join(BASE_DIR, "outputs")
CONFIG_DIR = os.path.join(BASE_DIR, "config")
os.makedirs(OUTPUT_DIR, exist_ok=True)

today = datetime.now().strftime("%Y-%m-%d")
news_path = os.path.join(OUTPUT_DIR, f"related_news_{today}.json")

# === OpenAI API Key ===
key_path = os.path.join(CONFIG_DIR, "openai_key.txt")
if not os.path.exists(key_path):
    print(f"âŒ OpenAI Key íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {key_path}")
    exit()

client = OpenAI(api_key=open(key_path, "r", encoding="utf-8").read().strip())

# === ë‰´ìŠ¤ ê²€ìƒ‰ í‚¤ì›Œë“œ ===
KEYWORDS = ["ëŒ€í†µë ¹ ì§€ì§€ìœ¨", "êµ­ë¯¼ì˜í˜", "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹", "ì •ì¹˜ ì´ìŠˆ", "ì‚¬íšŒ ì´ìŠˆ"]

def fetch_naver_news(keyword: str, limit: int = 5):
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ nê°œ ì œëª© + URL ì¶”ì¶œ"""
    url = f"https://search.naver.com/search.naver?where=news&query={keyword}&sm=tab_opt&sort=1"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    items = soup.select(".news_tit")[:limit]
    return [{"title": i["title"], "url": i["href"]} for i in items]

# === ë‰´ìŠ¤ ìˆ˜ì§‘ ===
collected_news = []
for kw in KEYWORDS:
    try:
        articles = fetch_naver_news(kw)
        if articles:
            collected_news.extend(articles)
    except Exception as e:
        print(f"âš ï¸ {kw} ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

# === AI ìš”ì•½ ===
titles = "\n".join([f"- {n['title']}" for n in collected_news])
prompt = f"""
ë‹¤ìŒì€ ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ ì œëª© ëª©ë¡ì…ë‹ˆë‹¤.
ê° ë‰´ìŠ¤ê°€ ëŒ€í†µë ¹ í˜¹ì€ ì •ë‹¹ ì§€ì§€ìœ¨ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆëŠ”ì§€
5ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•˜ê³ , í•µì‹¬ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ê°„ê²°í•œ ë¶„ì„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

{titles}
"""

try:
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5
    )
    summary = response.choices[0].message.content.strip()
except Exception as e:
    summary = f"âš ï¸ AI ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

# === ê²°ê³¼ ì €ì¥ ===
output_data = {
    "date": today,
    "keywords": KEYWORDS,
    "news_titles": collected_news,
    "summary": summary
}

with open(news_path, "w", encoding="utf-8") as f:
    json.dump(output_data, f, ensure_ascii=False, indent=2)

print(f"ğŸ—ï¸ ì£¼ìš” ë‰´ìŠ¤ ë¶„ì„ ì €ì¥ ì™„ë£Œ â†’ {news_path}")
print("ğŸ§  ìš”ì•½ ë¯¸ë¦¬ë³´ê¸° â†“\n")
print(summary)
