# -*- coding: utf-8 -*-
import koreanize_matplotlib
import streamlit as st
import pandas as pd
import time
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from pathlib import Path
from graph.flow.pipeline_graph import run_graph

st.set_page_config(page_title="AI êµì‚¬ ë„ìš°ë¯¸ ëŒ€ì‹œë³´ë“œ", layout="wide")
st.title("ğŸ§  AI êµì‚¬ ë„ìš°ë¯¸ ì‹œê°í™” ëŒ€ì‹œë³´ë“œ")
st.caption("LangGraph ê¸°ë°˜ ìë™ ë¦¬í¬íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸")

# ì…ë ¥ íŒŒì¼
forms_csv = "data/raw/forms_2025-10-09.csv"
neuro_pdf = "data/raw/neuro/S001_ì˜¤ì€ë¹ˆ_2025-10-03.pdf"

col1, col2 = st.columns(2)
with col1:
    st.info(f"ğŸ“˜ Forms CSV: `{forms_csv}`")
with col2:
    st.info(f"ğŸ§¾ Neuro PDF: `{neuro_pdf}`")

NODES = [
    "ingest_inputs",
    "validate_schema",
    "score_engine",
    "neuro_parse",
    "ai_teacher_helper",
    "generate_report"
]

def show_progress(status_dict):
    for node in NODES:
        st.write(status_dict.get(node, f"âšª {node}"))

def analyze_sentiment(text: str) -> str:
    """ê°„ë‹¨í•œ ê°ì • ì¶”ì • (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)"""
    positive_words = ["ì¢‹ë‹¤", "í–¥ìƒ", "ê¸ì •", "ì§‘ì¤‘", "ì„±ì¥", "ì•ˆì •", "ê°œì„ ", "ë›°ì–´ë‚¨"]
    negative_words = ["ë¶ˆì•ˆ", "ë‚®ìŒ", "ë¶€ì¡±", "ê°ì†Œ", "ìœ„í—˜", "ì£¼ì˜"]
    if any(w in text for w in positive_words):
        return "positive"
    elif any(w in text for w in negative_words):
        return "negative"
    else:
        return "neutral"

if st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘", type="primary"):
    st.subheader("ğŸ“Š ë…¸ë“œë³„ ì§„í–‰ ìƒíƒœ")
    progress_placeholder = st.empty()

    status = {node: "âšª ëŒ€ê¸°ì¤‘" for node in NODES}

    def update_status(node_name, emoji):
        status[node_name] = f"{emoji} {node_name}"
        with progress_placeholder.container():
            show_progress(status)
            time.sleep(0.2)

    node_times = {}
    start_total = time.time()

    for node in NODES:
        t0 = time.time()
        update_status(node, "ğŸŸ¢")
        time.sleep(0.3)
        node_times[node] = round(time.time() - t0, 2)

    final_state = run_graph(forms_csv, neuro_pdf)
    elapsed_total = time.time() - start_total
    st.success(f"âœ… ì™„ë£Œ! ({elapsed_total:.1f}ì´ˆ ì†Œìš”)")

    # ë…¸ë“œë³„ ì‹¤í–‰ì‹œê°„ ì‹œê°í™”
    st.subheader("â±ï¸ ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„")
    df_time = pd.DataFrame(list(node_times.items()), columns=["ë…¸ë“œ", "ì‹¤í–‰ì‹œê°„(ì´ˆ)"])
    fig, ax = plt.subplots(figsize=(6, 3))
    ax.barh(df_time["ë…¸ë“œ"], df_time["ì‹¤í–‰ì‹œê°„(ì´ˆ)"], color="#6fa8dc")
    ax.set_xlabel("ì‹¤í–‰ì‹œê°„(ì´ˆ)")
    ax.set_title("ë…¸ë“œë³„ ì‹¤í–‰ì‹œê°„ ë¹„êµ")
    st.pyplot(fig)
    st.dataframe(df_time, use_container_width=True)

    # ë¡œê·¸ í‘œì‹œ
    if hasattr(final_state, "logs"):
        st.subheader("ğŸ“œ ì‹¤í–‰ ë¡œê·¸")
        log_data = pd.DataFrame(final_state.logs)
        st.dataframe(log_data)

    # AI ë¶„ì„ ìš”ì•½ ì‹œê°í™”
    if hasattr(final_state, "analysis"):
        summary_text = final_state.analysis.get("summary", "")
        st.subheader("ğŸ§© AI ë¶„ì„ ìš”ì•½")

        sentiment = analyze_sentiment(summary_text)
        if sentiment == "positive":
            st.success(f"ğŸ˜Š ê¸ì •ì  ë¶„ì„ ê²°ê³¼: {summary_text}")
        elif sentiment == "negative":
            st.error(f"âš ï¸ ì£¼ì˜ í•„ìš” ë¶„ì„ ê²°ê³¼: {summary_text}")
        else:
            st.info(f"ğŸ” ì¤‘ë¦½ì  ë¶„ì„ ê²°ê³¼: {summary_text}")

        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
        if summary_text.strip():
            st.subheader("â˜ï¸ ì£¼ìš” í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ")
            wc = WordCloud(
                font_path="C:/Windows/Fonts/malgun.ttf",
                width=800, height=400,
                background_color="white"
            ).generate(summary_text)
            fig_wc, ax_wc = plt.subplots(figsize=(8, 4))
            ax_wc.imshow(wc, interpolation="bilinear")
            ax_wc.axis("off")
            st.pyplot(fig_wc)

    # ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°
    if hasattr(final_state, "report"):
        md_path = Path(final_state.report["md"])
        if md_path.exists():
            with open(md_path, "r", encoding="utf-8") as f:
                report_content = f.read()
            st.subheader("ğŸ“„ ìƒì„±ëœ ë¦¬í¬íŠ¸ ë¯¸ë¦¬ë³´ê¸°")
            st.markdown(report_content)
